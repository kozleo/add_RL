{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5c1f35c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78f5f968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_space = Box(0, 1, shape=(2,))\n",
    "observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4f27e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocaineWorld(gym.Env):\n",
    "    \n",
    "\n",
    "    def __init__(self, actions=5, trial_length = 10,lever_light_on = 5):\n",
    "        \n",
    "        \n",
    "        self.time = 0 # time step within a single trial\n",
    "        self.trial_length = trial_length # length of trial\n",
    "        self.lever_light_on = lever_light_on # how long the lever light is on for \n",
    "        \n",
    "        self.observation_space = Box(0, 1, shape=(2,))\n",
    "\n",
    "        # We have actions, corresponding to \"press cocaine lever\", \"press sugar lever\", \"scratch butt\", etc\n",
    "        self.action_space = Discrete(actions)\n",
    "        \n",
    "        self.rewards = np.random.normal(0,1, self.action_space.n)\n",
    "        \n",
    "\n",
    "\n",
    "    def reset(self, seed = 42, options=None):\n",
    "        # We need the following line to seed self.np_random\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        self.time = 0\n",
    "        self.obs = [1, 0]\n",
    "        \n",
    "        return self.obs\n",
    "        \n",
    "      \n",
    "\n",
    "    def step(self, action):        \n",
    "        \n",
    "        terminated = self.time >= self.trial_length #check to make sure trial is not done\n",
    "        \n",
    "        reward = self.rewards[action] #compute reward\n",
    "        \n",
    "        self.time += 1 # go foward one timestep in trial   \n",
    "        \n",
    "        if self.time >= self.lever_light_on:\n",
    "            self.obs =  [0, 1]       \n",
    "        \n",
    "        \n",
    "        return self.obs, reward, terminated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5198033",
   "metadata": {},
   "source": [
    "# Train MLP on addiction task (very simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "57d9a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(sizes, activation=nn.Tanh, output_activation=nn.Identity):\n",
    "    # Build a feedforward neural network.\n",
    "    layers = []\n",
    "    for j in range(len(sizes)-1):\n",
    "        act = activation if j < len(sizes)-2 else output_activation\n",
    "        layers += [nn.Linear(sizes[j], sizes[j+1]), act()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def train(hidden_sizes=[32], lr=1e-2, \n",
    "          epochs=50, batch_size=5000):\n",
    "\n",
    "    # make environment, check spaces, get obs / act dims\n",
    "    env = CocaineWorld()\n",
    "\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    n_acts = env.action_space.n\n",
    "\n",
    "    # make core of policy network\n",
    "    logits_net = mlp(sizes=[obs_dim]+hidden_sizes+[n_acts])\n",
    "\n",
    "    # make function to compute action distribution\n",
    "    def get_policy(obs):\n",
    "        logits = logits_net(obs)\n",
    "        return Categorical(logits=logits)\n",
    "\n",
    "    # make action selection function (outputs int actions, sampled from policy)\n",
    "    def get_action(obs):\n",
    "        return get_policy(obs).sample().item()\n",
    "\n",
    "    # make loss function whose gradient, for the right data, is policy gradient\n",
    "    def compute_loss(obs, act, weights):\n",
    "        logp = get_policy(obs).log_prob(act)\n",
    "        return -(logp * weights).mean()\n",
    "\n",
    "    # make optimizer\n",
    "    optimizer = Adam(logits_net.parameters(), lr=lr)\n",
    "\n",
    "    # for training policy\n",
    "    def train_one_epoch():\n",
    "        # make some empty lists for logging.\n",
    "        batch_obs = []          # for observations\n",
    "        batch_acts = []         # for actions\n",
    "        batch_weights = []      # for R(tau) weighting in policy gradient\n",
    "        batch_rets = []         # for measuring episode returns\n",
    "        batch_lens = []         # for measuring episode lengths\n",
    "\n",
    "        # reset episode-specific variables\n",
    "        obs = env.reset()       # first obs comes from starting distribution\n",
    "        done = False            # signal from environment that episode is over\n",
    "        ep_rews = []            # list for rewards accrued throughout ep\n",
    "\n",
    "        # render first episode of each epoch\n",
    "        finished_rendering_this_epoch = False\n",
    "\n",
    "        # collect experience by acting in the environment with current policy\n",
    "        while True:               \n",
    "            \n",
    "\n",
    "            # save obs\n",
    "            batch_obs.append(obs)\n",
    "\n",
    "            # act in the environment\n",
    "            act = get_action(torch.as_tensor(obs, dtype=torch.float32))\n",
    "            obs, rew, done = env.step(act)\n",
    "\n",
    "            # save action, reward\n",
    "            batch_acts.append(act)\n",
    "            ep_rews.append(rew)\n",
    "\n",
    "            if done:\n",
    "                # if episode is over, record info about episode\n",
    "                ep_ret, ep_len = sum(ep_rews), len(ep_rews)\n",
    "                batch_rets.append(ep_ret)\n",
    "                \n",
    "\n",
    "                # the weight for each logprob(a|s) is R(tau)\n",
    "                batch_weights += [ep_ret] * ep_len\n",
    "\n",
    "                # reset episode-specific variables\n",
    "                obs, done, ep_rews = env.reset(), False, []\n",
    "                \n",
    "\n",
    "                # end experience loop if we have enough of it\n",
    "                if len(batch_obs) > batch_size:\n",
    "                    break\n",
    "\n",
    "                    \n",
    "        batch_obs = np.stack(batch_obs)       \n",
    "        batch_acts = np.stack(batch_acts) \n",
    "        batch_weights = np.stack(batch_weights)\n",
    "        \n",
    "        # take a single policy gradient update step\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = compute_loss(obs=torch.as_tensor(batch_obs, dtype=torch.float32),\n",
    "                                  act=torch.as_tensor(batch_acts, dtype=torch.int32),\n",
    "                                  weights=torch.as_tensor(batch_weights, dtype=torch.float32)\n",
    "                                  )\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        return batch_loss, batch_rets\n",
    "    \n",
    "    rewards_over_epochs = []\n",
    "\n",
    "    # training loop\n",
    "    for i in range(epochs):\n",
    "        batch_loss, batch_rets = train_one_epoch()\n",
    "        \n",
    "        print('epoch: %3d \\t loss: %.3f \\t return: %.3f'%\n",
    "                (i, batch_loss, np.mean(batch_rets)))\n",
    "\n",
    "        rewards_over_epochs.append(np.mean(batch_rets))\n",
    "\n",
    "    return rewards_over_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "433c5eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 \t loss: 5.677 \t return: 3.689\n",
      "epoch:   1 \t loss: 7.250 \t return: 4.863\n",
      "epoch:   2 \t loss: 8.363 \t return: 5.721\n",
      "epoch:   3 \t loss: 9.290 \t return: 6.575\n",
      "epoch:   4 \t loss: 9.726 \t return: 7.055\n",
      "epoch:   5 \t loss: 10.598 \t return: 8.027\n",
      "epoch:   6 \t loss: 10.785 \t return: 8.556\n",
      "epoch:   7 \t loss: 10.867 \t return: 9.033\n",
      "epoch:   8 \t loss: 10.891 \t return: 9.620\n",
      "epoch:   9 \t loss: 10.631 \t return: 9.937\n",
      "epoch:  10 \t loss: 10.234 \t return: 10.342\n",
      "epoch:  11 \t loss: 9.769 \t return: 10.712\n",
      "epoch:  12 \t loss: 9.279 \t return: 10.893\n",
      "epoch:  13 \t loss: 8.699 \t return: 11.126\n",
      "epoch:  14 \t loss: 7.951 \t return: 11.350\n",
      "epoch:  15 \t loss: 7.416 \t return: 11.447\n",
      "epoch:  16 \t loss: 6.690 \t return: 11.637\n",
      "epoch:  17 \t loss: 6.146 \t return: 11.721\n",
      "epoch:  18 \t loss: 5.473 \t return: 11.803\n",
      "epoch:  19 \t loss: 5.026 \t return: 11.880\n",
      "epoch:  20 \t loss: 4.630 \t return: 11.957\n",
      "epoch:  21 \t loss: 4.039 \t return: 11.964\n",
      "epoch:  22 \t loss: 3.680 \t return: 12.032\n",
      "epoch:  23 \t loss: 3.420 \t return: 12.042\n",
      "epoch:  24 \t loss: 2.990 \t return: 12.086\n",
      "epoch:  25 \t loss: 2.710 \t return: 12.115\n",
      "epoch:  26 \t loss: 2.304 \t return: 12.151\n",
      "epoch:  27 \t loss: 2.046 \t return: 12.154\n",
      "epoch:  28 \t loss: 1.962 \t return: 12.179\n",
      "epoch:  29 \t loss: 1.615 \t return: 12.199\n",
      "epoch:  30 \t loss: 1.549 \t return: 12.195\n",
      "epoch:  31 \t loss: 1.336 \t return: 12.206\n",
      "epoch:  32 \t loss: 1.181 \t return: 12.211\n",
      "epoch:  33 \t loss: 1.008 \t return: 12.222\n",
      "epoch:  34 \t loss: 0.930 \t return: 12.225\n",
      "epoch:  35 \t loss: 0.853 \t return: 12.234\n",
      "epoch:  36 \t loss: 0.723 \t return: 12.245\n",
      "epoch:  37 \t loss: 0.788 \t return: 12.243\n",
      "epoch:  38 \t loss: 0.551 \t return: 12.245\n",
      "epoch:  39 \t loss: 0.580 \t return: 12.252\n",
      "epoch:  40 \t loss: 0.572 \t return: 12.248\n",
      "epoch:  41 \t loss: 0.526 \t return: 12.252\n",
      "epoch:  42 \t loss: 0.474 \t return: 12.256\n",
      "epoch:  43 \t loss: 0.435 \t return: 12.258\n",
      "epoch:  44 \t loss: 0.460 \t return: 12.249\n",
      "epoch:  45 \t loss: 0.539 \t return: 12.254\n",
      "epoch:  46 \t loss: 0.359 \t return: 12.259\n",
      "epoch:  47 \t loss: 0.329 \t return: 12.260\n",
      "epoch:  48 \t loss: 0.391 \t return: 12.253\n",
      "epoch:  49 \t loss: 0.344 \t return: 12.258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aae8f313970>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "lr = 1e-2\n",
    "\n",
    "\n",
    "rewards_over_epochs = train(lr=lr,epochs=50, batch_size=5000)\n",
    "\n",
    "plt.plot(rewards_over_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:leokoz8-add_RL] *",
   "language": "python",
   "name": "conda-env-leokoz8-add_RL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
